{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the NOAA data buoys I would choose this one as an important and representative example:\n",
    "# Station MOK1  (Station Page) in Kaneohe Bay (MOK for Moku o Loe, Coconut Island, where HIMB is).\n",
    "# http://www.ndbc.noaa.gov/station_page.php?station=mokh1\n",
    "#      [displays station, past 24 hrs of data, links to older data at the bottom of the page]\n",
    "#      \"real-time data\" shows the past 45 days\n",
    "#      \"historic data\" shows past years by year, current year downloadable by month\n",
    "\n",
    "# Historic data is probably the best to use for a first example since it's stable (quality checked, not provisional)\n",
    "# and comes in reasonably big and useful chunks.\n",
    "  \n",
    "# The variable we care about for corals is collected as part of \"standard meteorological data\" suite, \n",
    "# and is Sea Surface Temperature, column heading WTMP in NOAA data files.\n",
    "# \"WTMP Sea surface temperature (Celsius). For buoys the depth is referenced to the hull's waterline. \n",
    "# For fixed platforms it varies with tide, but is referenced to, or near Mean Lower Low Water (MLLW).\"\n",
    "# - from http://www.ndbc.noaa.gov/measdes.shtml . \n",
    "\n",
    "# Example 1: I need to plot sea surface temperature (SST) data for 2014 and 2015 (bleaching years)., \n",
    "#     The historic data is stable, available for a year at a time, and comes in a slightly different text \n",
    "#     format than more recent data. I would find that linked from the Station Page as \"historic data\" link at the bottom:\n",
    "# http://www.ndbc.noaa.gov/station_history.php?station=mokh1\n",
    "\n",
    "#     From the historic data page http://www.ndbc.noaa.gov/station_history.php?station=mokh1\n",
    "# I choose historic -- standard meteorological data -- click on year links (2014) and choose .txt or .gz\n",
    "# (mokh1h2014.txt is at http://www.ndbc.noaa.gov/view_text_file.php?filename=mokh1h2014.txt.gz&dir=data/historical/stdmet/)\n",
    "# (mokh1h2014.txt.gz is at http://www.ndbc.noaa.gov/data/historical/stdmet/mokh1h2014.txt.gz)\n",
    "\n",
    "# One exercise I've done in R (presumably also doable in Python) is to download and plot \n",
    "# these datasets for a year at a time, or multiple years overlaid on an annual axis to see \n",
    "# variation, x axis running Jan-Dec (watch out for leap years). \n",
    "# There's some work required in (1) aggregating the parsed date and time into reasonable \n",
    "# columns to use for plotting (2) checking for and filling in missing date or time gaps with NA or blanks, \n",
    "# and converting the ubiquitous 999 to NA or blanks, (3) subsampling the data at regular intervals \n",
    "# if you just don't want to fool with that size dataset (first reading of the day) or \n",
    "# aggregating (daily average) - some of these interval choices or time averages may be impacted \n",
    "# by high-frequency down times (assumed to be equipment maintenance or self-checks), and especially \n",
    "# (4) potentially harvesting or exporting the resulting csv to use in other programs (a very common need), \n",
    "# in the process deleting columns of no interest. (5) Also - if I recall, NOAA .txt datasets have 2 (maybe 3) \n",
    "# top lines taken up in specifying column header information, and for any reasonable kind of downstream use, \n",
    "# one will want to export a clean csv with column headings of: one line only, no spaces or special characters, \n",
    "# only numbers letters dashes and underscores, maybe the ability to rename with something more explicit like \n",
    "# WaterTemp_degC instead of  WTMP (which even today took some lookup time to rediscover/re-remember \n",
    "# that WTMP actually meant SST). \n",
    "\n",
    "# Additional feature. It can be useful to add to the graph (1) a straight horizontal line of one's \n",
    "# choosing (e.g., mean annual temperature, or user-specified physiological tolerance temperature thresholds for \n",
    "#           (a) coral stress or (b) coral death). \n",
    "\n",
    "# Additional feature. With access to many years' worth of data, it would also be useful to plot selected years \n",
    "# along with an average temperature (same time interval as the year being plotted - such as daily) for \n",
    "# the past decade, or all years, to compare magnitude and timing of temperature spikes during bleaching years \n",
    "# to the usual temperature for that time of year (and the user knowing from other data, such as field observations,\n",
    "# when the first signs of bleaching or paling were seen for that year).\n",
    "\n",
    "# Additional feature. Note that the \"bleaching season\" tends to occur in the fall, so to observe \n",
    "# full warming and recovery cycles, people might want to offset the starting month (Apr-Mar rather than Jan-Dec). \n",
    "# Nice but maybe later, as with the other \"additional features\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import urllib.request, json\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "#Set URL of notebook to http://localhost:8888/notebooks/github_repos/Mok1-Sea-Data/Ouida.ipynb?docID=65bbd72fc0b44da390f3a2007600d6be&var=65bbd72fc0b44da390f3a2007600d6be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function getQueryStringValue (key)\n",
       "{  \n",
       "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
       "}\n",
       "IPython.notebook.kernel.execute(\"docID='\".concat(getQueryStringValue(\"docID\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"var='\".concat(getQueryStringValue(\"var\")).concat(\"'\"));\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"docID='\".concat(getQueryStringValue(\"docID\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"var='\".concat(getQueryStringValue(\"var\")).concat(\"'\"));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65bbd72fc0b44da390f3a2007600d6be\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#construct url from variable\n",
    "cinergi_url = \"http://cinergi.sdsc.edu/geoportal/rest/metadata/item/\" + docID\n",
    "\n",
    "test_data = ''\n",
    "with urllib.request.urlopen(cinergi_url) as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    data = data[\"_source\"][\"links_s\"]\n",
    "    test_data = pd.read_csv(data, delim_whitespace=True, header=[0,1], na_values=['99.0','999.0','99.00','999','9999.0' ])\n",
    "\n",
    "# Preview Data from Cinergi URL\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file we are working with\n",
    "# file1_url = \"http://www.ndbc.noaa.gov/view_text_file.php?filename=mokh1h2014.txt.gz&dir=data/historical/stdmet/\"\n",
    "\n",
    "data = []\n",
    "#Current ways of importing the files\n",
    "file1_local = 'mokh1h2014.txt'\n",
    "file2_local = 'mokh1h2015.txt'\n",
    "\n",
    "# Reading in the files\n",
    "df = pd.read_csv(file1_local, delim_whitespace=True, header=[0,1], na_values=['99.0','999.0','99.00','999','9999.0' ])\n",
    "df2= pd.read_csv(file2_local, delim_whitespace=True, header = [0,1], na_values =['99.0','999.0','99.00','999','9999.0' ])\n",
    "data.append(df)\n",
    "data.append(df2)\n",
    "\n",
    "df.fillna('')\n",
    "df2.fillna('')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_column_names(df):\n",
    "    new_header = []\n",
    "    for i in (list(df.columns.values)):\n",
    "        if len(i) == 1:\n",
    "            new_header.append(i[0])\n",
    "        elif len(i) == 2:\n",
    "            new_header.append('%s (%s)'%(i[0],i[1]))\n",
    "    df.columns = new_header\n",
    "    return df\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = simplify_column_names(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a datetime object based on the dates and times and appends to the existing dataframe\n",
    "\n",
    "#function to streamline the operation\n",
    "def createDateTime(df):\n",
    "    df_temp = df[['#YY (#yr)', 'MM (mo)','DD (dy)','hh (hr)','mm (mn)']].copy()\n",
    "    df_temp.columns = ['year', 'month', 'day', 'hour', 'minute']\n",
    "    df_temp = pd.to_datetime(df_temp)\n",
    "\n",
    "    df_temp = pd.DataFrame({'date_time': df_temp})\n",
    "    df = pd.concat([df,df_temp], axis = 1)\n",
    "    return df\n",
    "\n",
    "df = createDateTime(df)\n",
    "df2 = createDateTime(df2)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = createDateTime(data[i])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i]['date_time'] = data[i]['date_time'].apply(lambda x: x.replace(year= 2014))\n",
    "\n",
    "\n",
    "data[0],data[1]\n",
    "#More sophisticated code must be implemented here to handle multiple data sets.\n",
    "#Takes the 2015 dataset and moves the data down by 1 in order to maintain the same year.\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of the image based on values of WTMP (Can be changed to other variables)\n",
    "\n",
    "#Sets the size of the figure in the notebook\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (25, 15)\n",
    "\n",
    "\n",
    "#Plots the figure, configures settings about the plot\n",
    "plt.plot(data[0]['date_time'],data[0]['WTMP (degC)'])\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "#fontsize of the tick labels\n",
    "plt.rc('xtick', labelsize=15) \n",
    "plt.rc('ytick', labelsize = 15)\n",
    "\n",
    "#Size of ticks\n",
    "plt.tick_params(direction='out', length=10, width=2,)\n",
    "\n",
    "#X and Y labels\n",
    "plt.xlabel('Time',fontsize=18)\n",
    "plt.ylabel('WTMP (degC)',fontsize=18)\n",
    "\n",
    "\n",
    "#Second Plot\n",
    "\n",
    "plt.plot(data[1]['date_time'],data[1]['WTMP (degC)'],color = 'red')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "\n",
    "\n",
    "key1 = mpatches.Patch(color='blue', label='2014')\n",
    "key2 = mpatches.Patch(color='red', label='2015')\n",
    "\n",
    "plt.legend(handles=[key1,key2])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def changeColumnNames(df):\n",
    "    df.columns = ['year','month','day','hour','minute','WDIR','WSPD','GST','WVHT','DPD','APD','MWD','PRES','ATMP','WTMP','DEWP','VIS','TIDE',\n",
    "                  'date_time']\n",
    "    return df\n",
    "\n",
    "\n",
    "df_test = changeColumnNames(df)\n",
    "df_test2 = changeColumnNames(df2)\n",
    "\n",
    "result = pd.concat([df_test,df_test2])\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(result, index=['month'],columns=['year'], values=['WTMP'])\n",
    "piv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
